{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db273fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f08c5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "raw = [\"I feel hungry.\t나는 배가 고프다.\",\n",
    "       \"Pytorch is very easy.\t파이토치는 매우 쉽다.\",\n",
    "       \"Pytorch is a framework for deep learning.\t파이토치는 딥러닝을 위한 프레임워크이다.\",\n",
    "       \"Pytorch is very clear to use.\t파이토치는 사용하기 매우 직관적이다.\"]\n",
    "\n",
    "SOS = 0\n",
    "EOS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78384b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict형태로 단어집합 만들기\n",
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.vocab2idx = {'<SOS>':SOS, '<EOS>':EOS}\n",
    "        self.idx2vocab = {SOS:'<SOS>', EOS:'<EOS>'}\n",
    "        self.vocab_cnt = {}\n",
    "        self.n_vocab = len(self.vocab2idx)\n",
    "    def add_vocab(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            \n",
    "            # key, value 둘 모두 word가 될 수 있다\n",
    "            if word not in self.vocab2idx:\n",
    "                \n",
    "                # 새로운 단어를 발견하면 vocab2idx 맨 뒤에 추가\n",
    "                self.vocab2idx[word] = self.n_vocab\n",
    "                \n",
    "                # 새로운 단어를 발견하면 cnt는 1, 같은 단어 발견하면 1씩 추가\n",
    "                self.vocab_cnt[word] = 1\n",
    "                \n",
    "                # vocab2idx 거꾸로만 하면 됨\n",
    "                self.idx2vocab[self.n_vocab] = word\n",
    "                self.n_vocab += 1\n",
    "            else:\n",
    "                self.vocab_cnt[word] += 1\n",
    "\n",
    "                \n",
    "# 최대 길이가 넘는 문장은 버리기                \n",
    "def filter_pair(pair, source_max_length, target_max_length):\n",
    "    # pair[0] == encoder 입력 문장 == source input\n",
    "    # pair[1] == decoder 입력 문장 == target input\n",
    "    return len(pair[0].split(' ')) < source_max_length and len(pair[1].split(' ') < target_max_length)\n",
    "\n",
    "# 분절 + 소문자화 + 인코더 입력 데이터 / 디코더 입력 데이터 분리\n",
    "def preprocess(corpus, source_max_length, target_max_length):\n",
    "    pairs = []\n",
    "    for line in corpus:\n",
    "        # X, Y 분절 + 소문자화\n",
    "        splower = [s for s in line.strip().lower().split('\\t')]\n",
    "        pairs.append(splower)\n",
    "    \n",
    "    pairs = [pair for pair in pairs if filter_pair(pair, source_max_length, target_max_length)]\n",
    "    \n",
    "    source_vocab = Vocab()\n",
    "    target_vocab = Vocab()\n",
    "    \n",
    "    for pair in pairs:\n",
    "        source_vocab.add_vocab(pair[0])\n",
    "        target_vocab.add_vocab(pair[1])\n",
    "    \n",
    "    # pairs는결국 source_vocab과 target_vocab의 합집합이다\n",
    "    return pairs, source_vocab, target_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46796be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, m):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.embedding = nn.Embedding(vocab_size, m)\n",
    "    \n",
    "        units = m # 뉴런개수와 input_dim이 우연히 같을 뿐 혼동 ㄴㄴ\n",
    "        self.lstm = nn.LSTM(m, units)\n",
    "        \n",
    "    def forward(self, inputs, h0c0): # h0c0 == (h0, c0)\n",
    "        inputs = self.embedding(inputs).view(1, 1, -1) # flatten ??\n",
    "        output, h0c0 = self.lstm(inputs, h0c0)\n",
    "        return output, h0c0\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, m): # 인코더랑 디코더 vocab_size는 다를 수 있다\n",
    "        super().__init__()\n",
    "        self.m = m\n",
    "        self.embedding = nn.Embedding(vocab_size, m)\n",
    "        units = m # 이것도 우연임\n",
    "        self.lstm = nn.LSTM(m, units)\n",
    "        self.out = nn.Linear(m, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, inputs, h0c0):\n",
    "        inputs = self.embedding(inputs).view(1, 1, -1)\n",
    "        output, h0c0 = self.lstm(inputs, h0c0)\n",
    "        y = self.softmax(self.out(output[0])) # N=1개씩 step을 계산하기 위해 output[0]\n",
    "        return y, h0c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bdb452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "222.848px",
    "left": "716.429px",
    "right": "20px",
    "top": "-0.999992px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
