{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08329e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('testing.json', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    data = data[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e599e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "297c5f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "checkpoint = 'facebook/m2m100_418M'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(checkpoint)\n",
    "model.to(device)\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(checkpoint, batched=True)\n",
    "\n",
    "def tokenize_function(data):\n",
    "    samples = []\n",
    "    tokenized_data = {'input_ids':None, 'attention_mask':None, 'labels':None}\n",
    "    for line in data:\n",
    "        tokenizer.src_lang = line['src_lang']\n",
    "        inputs = tokenizer(line['src_text'], return_tensors='pt')\n",
    "        tokenizer.tgt_lang = line['tgt_lang']\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = tokenizer(line['tgt_text'], return_tensors='pt').input_ids\n",
    "        tokenized_data['input_ids'] = inputs['input_ids'].reshape(-1)\n",
    "        tokenized_data['attention_mask'] = inputs['attention_mask'].reshape(-1)\n",
    "        tokenized_data['labels'] = labels.reshape(-1)\n",
    "        samples.append(tokenized_data)\n",
    "    return samples\n",
    "\n",
    "tokenized_data = tokenize_function(data)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d58006ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': tensor([128052,    244,  14653,  20104,  16258,  44668,  28012,   8990,   3660,\n",
       "            4813,  52890,   5448,   8726,   1452,  36617,     12,    522,  12700,\n",
       "            2973, 119686,    668,  27253,  12689,   7796,   3639,    526,   7375,\n",
       "            4463,  12094,   5757,  56083,  29147,  45680,  96238,   1452,  17736,\n",
       "          107521,      4,   5117,   7796,   3639,   1028,  67777,    273,  34452,\n",
       "             526,  28012,   8990,   3660,  50838,   1384,  68882,    949,   5448,\n",
       "            8726,  36169,  63767,  10340,      5,      2]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  'labels': tensor([128022,  53191,   1197,    441,  38997,    432,   1197,     33,  14653,\n",
       "            3900,  15945,   3593,    193,   1197,   2594,   1006,   1713,    963,\n",
       "             432,   5273,  33427,    353, 102515,  38611,     28,  74179,   3381,\n",
       "           26432,     55,    881,   1197, 126066, 124655,  69086,    963,    432,\n",
       "           38534,  58015, 121822,   7258,  59663,    637,    202,  62843,      4,\n",
       "            1019,  37502, 120115,    353,  65265,  69086,   3699,  13635,    667,\n",
       "           26928, 115368,  15911,  63245,    193, 120067,   1019, 103956,   1320,\n",
       "            7061,    397,      5,      2])},\n",
       " {'input_ids': tensor([128052,    244,  14653,  20104,  16258,  44668,  28012,   8990,   3660,\n",
       "            4813,  52890,   5448,   8726,   1452,  36617,     12,    522,  12700,\n",
       "            2973, 119686,    668,  27253,  12689,   7796,   3639,    526,   7375,\n",
       "            4463,  12094,   5757,  56083,  29147,  45680,  96238,   1452,  17736,\n",
       "          107521,      4,   5117,   7796,   3639,   1028,  67777,    273,  34452,\n",
       "             526,  28012,   8990,   3660,  50838,   1384,  68882,    949,   5448,\n",
       "            8726,  36169,  63767,  10340,      5,      2]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  'labels': tensor([128022,  53191,   1197,    441,  38997,    432,   1197,     33,  14653,\n",
       "            3900,  15945,   3593,    193,   1197,   2594,   1006,   1713,    963,\n",
       "             432,   5273,  33427,    353, 102515,  38611,     28,  74179,   3381,\n",
       "           26432,     55,    881,   1197, 126066, 124655,  69086,    963,    432,\n",
       "           38534,  58015, 121822,   7258,  59663,    637,    202,  62843,      4,\n",
       "            1019,  37502, 120115,    353,  65265,  69086,   3699,  13635,    667,\n",
       "           26928, 115368,  15911,  63245,    193, 120067,   1019, 103956,   1320,\n",
       "            7061,    397,      5,      2])}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39564ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        super().__init__()\n",
    "        self.samples = samples\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "# def collate_fn_pad(batch):\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "dataset = MyDataset(tokenized_data)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=2, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54522902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epoch = 10\n",
    "num_tot_steps = num_epoch * len(dataloader)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "lr_scheduler = get_scheduler('linear', optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_tot_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8e6b32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06964456dff490aa292165c4aa9190d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 502.00 MiB (GPU 0; 6.00 GiB total capacity; 4.43 GiB already allocated; 44.50 MiB free; 4.58 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-222304b6adc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mlr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cpb06gamen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cpb06gamen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cpb06gamen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\optimization.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    349\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m                 \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eps\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lr\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 502.00 MiB (GPU 0; 6.00 GiB total capacity; 4.43 GiB already allocated; 44.50 MiB free; 4.58 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pbar = tqdm(range(num_tot_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epoch):\n",
    "    train_loss = 0.0\n",
    "    for batch in dataloader:\n",
    "        batch = {k:v.to(device) for k, v in batch.items()}\n",
    "        output = model(**batch)\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        pbar.update(1)\n",
    "    train_loss /= num_tot_steps\n",
    "    print(f'train loss : {train_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699a763f",
   "metadata": {},
   "source": [
    "## Train / Test Split 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3885d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-f560f2d793950f4e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to C:\\Users\\CPB06GameN\\.cache\\huggingface\\datasets\\json\\default-f560f2d793950f4e\\0.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75b28a098be4163aca24cfe2b7ffd92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5309a71f534ed38813e660a3e428af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff6aef181ab4460bf1d7fd87473dab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "raw_dataset = Dataset.from_json('testing.json')\n",
    "tokenized_dataset = raw_dataset.map(tokenize_function, batched=True, num_proc=4)\n",
    "tokenized_dataset = tokenized_dataset.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5fd897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "298.847px",
    "left": "884.531px",
    "right": "20px",
    "top": "-11px",
    "width": "311px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
