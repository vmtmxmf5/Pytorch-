{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "144176b6",
   "metadata": {},
   "source": [
    "## 결론\n",
    "\n",
    "1. MT5는 Fine-tuning 없이 번역 추론이 거의 **불가능**하다 (self-supervised learning만 했기 때문)  \n",
    "2. MT5 파라미터 수는 base 모델의 경우 약 5억 8천만, small 모델은 3억개 가량이다  \n",
    "\n",
    "3. 장비가 부족하여 **MT5와 M2M의 공정한 비교가 불가능**하다  \n",
    "    - 혹시 각 모델이 같은 Dataset을 대상으로 BLEU score를 계산한 적이 있는지 M2M, MT5 Paper를 찾아보았으나, 그런 경우는 없었다  \n",
    "    - 그나마 비슷한 실험으로 toward datascience에 게재된 글이 있으나, 공정한 비교가 아니었다  \n",
    "    - MT5의 경우 supervised learning이 안 된 모델인 반면, M2M은 pretrain된 모델을 가져와서 같은 양을 학습시켰기 때문에  \n",
    "    - 당연히 M2M의 성능이 높을 수 밖에 없는 실험설계였다 (같은 데이터셋, 같은 epoch 횟수)  \n",
    "    - https://towardsdatascience.com/comparing-facebooks-m2m-to-mt5-in-low-resources-translation-english-yoruba-ef56624d2b75\n",
    "    - 그래서 직접 학습을 하여 비교하려 했으나, 시간이 너무 오래 걸려 진행이 불가능했다  \n",
    "    - 노트북 GPU memory 문제 때문에 CPU로 학습을 진행해야 해서 너무 오래 걸림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a610f22",
   "metadata": {},
   "source": [
    "### MT5에 사용된 mC4 데이터셋(101개 언어) 예시\n",
    "\n",
    "|content-length|content-type|text|timestamp|url|\n",
    "|-|-|-|-|-|\n",
    "|43557|text/plain|RaptorDB - the Key Value Store - CodeProject 13,046,356 members (108,633 online)Last Visit: 31-Dec-99 18:00 Last Update: 23-Jul-17 11:31Refresh« Prev1234567891011 Next »|2017-07-23T21:31:05Z|https://www.codeproject.com/Articles/190504/RaptorDB? [...]|\n",
    "|10425|text/plain|Buy Mens Troy Lee Designs Clothing at Wheelies, Free UK delivery Top Brands Tenn (62) Tenn (62) Mens Troy Lee Designs Clothing|2017-01-18T20:23:44Z|http://www.wheelies.co.uk/troy-lee-designs-mens-clothing|\n",
    "|4139|text/plain|The Teachers' Lounge® (2 Ea) Nursery Rhymes Dvd Package Dimensions: Length 7.50\" Width 5.38\" Height 1.12\" Item Number: RL382BN|2019-11-22T12:46:19Z|https://www.the-teachers-lounge.com/product/-2-ea-nurser [...]|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79f2d1e",
   "metadata": {},
   "source": [
    "### 모델 크기 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0c1cbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MT5ForConditionalGeneration, M2M100ForConditionalGeneration\n",
    "\n",
    "mt5_base = MT5ForConditionalGeneration.from_pretrained('google/mt5-base')\n",
    "mt5_small = MT5ForConditionalGeneration.from_pretrained('google/mt5-small')\n",
    "m2m = M2M100ForConditionalGeneration.from_pretrained('facebook/m2m100_418M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910f394",
   "metadata": {},
   "source": [
    "#### 결과  \n",
    "파라미터 개수 비교 (MT5 base, MT5 small, M2M 418m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bf24cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- # of param -----\n",
      "MT5 base : 582,401,280\n",
      "MT5 small : 300,176,768\n",
      "M2M : 486,006,784\n"
     ]
    }
   ],
   "source": [
    "def model_size(m):\n",
    "    return sum(p.numel() for p in m.parameters())\n",
    "\n",
    "print('----- # of param -----')\n",
    "print(f'MT5 base : {model_size(mt5_base):,}')\n",
    "print(f'MT5 small : {model_size(mt5_small):,}')\n",
    "print(f'M2M : {model_size(m2m):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b0c079",
   "metadata": {},
   "source": [
    "### MT5 번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "54f3c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MT5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "checkpoint = 'google/mt5-base'\n",
    "model = MT5ForConditionalGeneration.from_pretrained(checkpoint)\n",
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be24df7b",
   "metadata": {},
   "source": [
    "#### 결과\n",
    "**MT5는 self-supervised 학습만** 진행하고, supervised 학습을 진행하지 않아서 **fine-tuning 없이**는 번역이 제대로 되지 않는다  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d5a762d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<extra_id_0> Korean']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'translate English to Korean: There is an apple'\n",
    "token = tokenizer(text, return_tensors='pt')\n",
    "enc = model.generate(**token)\n",
    "dec = tokenizer.batch_decode(enc, skip_special_tokens=True)\n",
    "dec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e8b4a",
   "metadata": {},
   "source": [
    "#### 근거\n",
    "실제 mC4 데이터 일부를 가지고 NER 추론 시 정상적으로 작동한다  \n",
    "다만, 번역은 supervised 학습을 하지 않았기 때문에 위와 같이 ['<extra_id_0> Korean'] 으로 결과가 출력되는 것이다\n",
    "\n",
    "- **ref**  \n",
    "mT5 개발자 언급 : https://github.com/huggingface/transformers/issues/8704#issuecomment-732255178  \n",
    "HuggingFace MT5 설명 NOTE 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2fd044bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<extra_id_0> Online | Cheapest Online Shopping']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Buy Mens Troy Lee Designs Clothing <extra_id_1> Wheelies'\n",
    "token = tokenizer(text, return_tensors='pt')\n",
    "enc = model.generate(**token)\n",
    "dec = tokenizer.batch_decode(enc, skip_special_tokens=True)\n",
    "dec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a766c78",
   "metadata": {},
   "source": [
    "### T5 번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a6befd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "checkpoint = 't5-base'\n",
    "model = T5ForConditionalGeneration.from_pretrained(checkpoint)\n",
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "971b1468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Es gibt einen Apfel']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'translate English to Korean: There is an apple'\n",
    "token = tokenizer(text, return_tensors='pt')\n",
    "enc = model.generate(**token)\n",
    "dec = tokenizer.batch_decode(enc, skip_special_tokens=True)\n",
    "dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9336491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Il y a une pomme']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'translate English to French: There is an apple'\n",
    "token = tokenizer(text, return_tensors='pt')\n",
    "enc = model.generate(**token)\n",
    "dec = tokenizer.batch_decode(enc, skip_special_tokens=True)\n",
    "dec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c64f2f2",
   "metadata": {},
   "source": [
    "#### 결과\n",
    "T5의 경우 **한국어 번역을 따로** 학습해야 한다  \n",
    "fine-tuning을 하지 않을 경우 한국어 번역 시도 시 독일어로 번역이 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a625f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11768ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MT5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import AdamW\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoint = 'google/mt5-small'\n",
    "model = MT5ForConditionalGeneration.from_pretrained(checkpoint)\n",
    "model.to(device)\n",
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b25e67f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = pd.read_json(path)[['src_text', 'tgt_text']]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        df = self.data.loc[index]\n",
    "        inputs = self.tokenizer(df['src_text'], return_tensors='pt')\n",
    "        with self.tokenizer.as_target_tokenizer():\n",
    "            labels = self.tokenizer(df['tgt_text'], return_tensors='pt').input_ids\n",
    "        inputs['input_ids'] = inputs['input_ids'].to(device)\n",
    "        inputs['attention_mask'] = inputs['attention_mask'].to(device)\n",
    "        inputs['labels'] = labels.to(device)\n",
    "        length = (inputs['input_ids'].shape[1], inputs['attention_mask'].shape[1], inputs['labels'].shape[1])\n",
    "        return (inputs, length)\n",
    "\n",
    "def collate(batch):\n",
    "    batch, length = zip(*batch)\n",
    "    ids, mask, label = zip(*length)\n",
    "    max_ids, max_mask, max_label = max(ids), max(mask), max(label)\n",
    "    ids, mask, label = list(ids), list(mask), list(label)\n",
    "    \n",
    "    ids_res, mask_res, label_res = [], [], []\n",
    "    for i, sample in enumerate(batch):\n",
    "        len_ids = max_ids - ids[i]\n",
    "        len_mask = max_mask - mask[i]\n",
    "        len_label = max_label - label[i]\n",
    "        ids_tensor = torch.cat([sample['input_ids'], torch.tensor([[tokenizer.pad_token_id] * len_ids], device=device)], dim=1)\n",
    "        mask_tensor = torch.cat([sample['attention_mask'], torch.tensor([[0] * len_mask], device=device)], dim=1)\n",
    "        label_tensor = torch.cat([sample['labels'], torch.tensor([[tokenizer.pad_token_id] * len_label], device=device)], dim=1)\n",
    "        ids_res.append(ids_tensor)\n",
    "        mask_res.append(mask_tensor)\n",
    "        label_res.append(label_tensor)\n",
    "    ids_batch = torch.cat(ids_res, dim=0)\n",
    "    mask_batch = torch.cat(mask_res, dim=0)\n",
    "    label_batch = torch.cat(label_res, dim=0)\n",
    "    return {'input_ids':ids_batch, 'attention_mask':mask_batch, 'labels':label_batch}\n",
    "    \n",
    "dataset = CustomDataset('test3.json', tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fe14e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d0ce0ed9034d09b26735e7803dfcb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 490.00 MiB (GPU 0; 6.00 GiB total capacity; 4.04 GiB already allocated; 128.50 MiB free; 4.49 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1af3385916dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mleng\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cpb06gamen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cpb06gamen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\optimization.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    338\u001b[0m                     \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"exp_avg\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m                     \u001b[1;31m# Exponential moving average of squared gradient values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m                     \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"exp_avg_sq\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_avg_sq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"exp_avg\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"exp_avg_sq\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 490.00 MiB (GPU 0; 6.00 GiB total capacity; 4.04 GiB already allocated; 128.50 MiB free; 4.49 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "torch.set_printoptions(precision=8, sci_mode=False)\n",
    "num_epochs = 10\n",
    "num_training_steps = num_epochs * len(dataloader)\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    leng = 0\n",
    "    for batch in dataloader:\n",
    "        batch = {k:v.to(device).long() for k, v in batch.items()}\n",
    "        output = model(**batch, decoder_input_ids=batch['labels'])\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        leng += 1\n",
    "        moving_loss = train_loss / leng\n",
    "        tqdm.set_postfix(Loss=f'{moving_loss}')\n",
    "        tqdm.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c887173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
