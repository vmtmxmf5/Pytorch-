{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32899e40",
   "metadata": {},
   "source": [
    "## Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6d7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "\n",
    "checkpoint = 'C:/Users/CPB06GameN/Downloads/voiceprint/m2m100_418M'\n",
    "teacher_model = M2M100ForConditionalGeneration.from_pretrained(checkpoint)\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605c5e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M2M100ForConditionalGeneration(\n",
       "  (model): M2M100Model(\n",
       "    (shared): Embedding(128112, 1024, padding_idx=1)\n",
       "    (encoder): M2M100Encoder(\n",
       "      (embed_tokens): Embedding(128112, 1024, padding_idx=1)\n",
       "      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): M2M100Decoder(\n",
       "      (embed_tokens): Embedding(128112, 1024, padding_idx=1)\n",
       "      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=128112, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6de82c",
   "metadata": {},
   "source": [
    "## Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91cd0ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length=100):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tok_emb = nn.Embedding(input_dim, hid_dim)\n",
    "        self.pos_emb = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device) for _ in range(n_layers)])\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim], device=device))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, src, src_mask):\n",
    "        batch_size = src.shape[0]\n",
    "        src_len = src.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, src_len, device=self.device).unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "        pos = self.pos_emb(pos)\n",
    "        emb = self.tok_emb(src) * self.scale\n",
    "        src = self.dropout(pos + emb)\n",
    "\n",
    "        for layers in self.layers:\n",
    "            src = layers(src, src_mask)\n",
    "        return src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5262e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
    "        super().__init__()\n",
    "        self.self_attention = MultiHeadAttention(hid_dim, n_heads, dropout, device)\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.feedforward = PositionWiseFeedForward(hid_dim, pf_dim, dropout)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, src, src_mask):\n",
    "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
    "        src = self.self_attn_layer_norm(self.dropout(_src) + src)\n",
    "        _src = self.feedforward(src)\n",
    "        src = self.ff_layer_norm(self.dropout(_src) + src)\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b043638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = hid_dim // n_heads\n",
    "\n",
    "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim], device=device))\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.shape[0]\n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "    \n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        attention = torch.softmax(energy, dim=-1)\n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        x = x.view(batch_size, -1, self.hid_dim)\n",
    "        x = self.fc_o(x)\n",
    "        return x, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2dbac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
    "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
    "        x = self.fc_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68ef6a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length=100):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tok_emb = nn.Embedding(output_dim, hid_dim)\n",
    "        self.pos_emb = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, n_heads, pf_dim, dropout, device) for _ in range(n_layers)])\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim], device=device))\n",
    "    def forward(self, tgt, enc_src, tgt_mask, src_mask):\n",
    "        batch_size = tgt.shape[0]\n",
    "        tgt_len = tgt.shape[1]\n",
    "        pos = torch.arange(0, tgt_len, device=self.device).unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "        tgt = self.dropout((self.tok_emb(tgt) * self.scale) + self.pos_emb(pos))\n",
    "\n",
    "        for layer in self.layers:\n",
    "            tgt, attention = layer(tgt, enc_src, tgt_mask, src_mask)\n",
    "        output = self.fc_out(tgt)\n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bbf43a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
    "        super().__init__()\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = MultiHeadAttention(hid_dim, n_heads, dropout, device)\n",
    "        self.enc_attention = MultiHeadAttention(hid_dim, n_heads, dropout, device)\n",
    "        self.feedforward = PositionWiseFeedForward(hid_dim, pf_dim, dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, tgt, enc_src, tgt_mask, src_mask):\n",
    "        _tgt, _ = self.self_attention(tgt, tgt, tgt, tgt_mask)\n",
    "        tgt = self.self_attn_layer_norm(tgt + self.dropout(_tgt))\n",
    "        \n",
    "        _tgt, attention = self.enc_attention(tgt, enc_src, enc_src, src_mask)\n",
    "        tgt = self.enc_attn_layer_norm(tgt + self.dropout(_tgt))\n",
    "        \n",
    "        _tgt = self.feedforward(tgt)\n",
    "        tgt = self.ff_layer_norm(tgt + self.dropout(_tgt))\n",
    "        return tgt, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67ebdd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, tgt_pad_idx, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.tgt_pad_idx = tgt_pad_idx\n",
    "        self.device = device\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask\n",
    "    def make_tgt_mask(self, tgt):\n",
    "        tgt_mask = (tgt != self.tgt_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_len = tgt.shape[1]\n",
    "        tgt_sub_mask = torch.tril(torch.ones((tgt_len, tgt_len), device=self.device)).bool()\n",
    "        tgt_mask = tgt_mask & tgt_sub_mask\n",
    "        return tgt_mask\n",
    "    def forward(self, input_ids, attention_mask, labels):\n",
    "        src = input_ids.type(torch.LongTensor)\n",
    "        src_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "        tgt = labels.type(torch.LongTensor)\n",
    "#         src_mask = self.make_src_mask(src)\n",
    "        tgt_mask = self.make_tgt_mask(tgt)\n",
    "        try:\n",
    "            enc_src = self.encoder(src, src_mask)\n",
    "            output, attention = self.decoder(tgt, enc_src, tgt_mask, src_mask)\n",
    "            return output\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abcc615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student Model Config\n",
    "INPUT_DIM, OUTPUT_DIM = tokenizer.vocab_size, tokenizer.vocab_size\n",
    "SRC_PAD_IDX, TGT_PAD_IDX = tokenizer.pad_token_id, tokenizer.pad_token_id\n",
    "HID_DIM = 256\n",
    "ENC_LAYERS, DEC_LAYERS = 3, 3\n",
    "ENC_HEADS, DEC_HEADS = 8, 8\n",
    "ENC_PF_DIM, DEC_PF_DIM = 512, 512\n",
    "ENC_DROPOUT, DEC_DROPOUT = 0.1, 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27c02527",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "enc = Encoder(INPUT_DIM, HID_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT, device)\n",
    "dec = Decoder(OUTPUT_DIM, HID_DIM, DEC_LAYERS, DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT, device)\n",
    "student_model = Seq2seq(enc, dec, SRC_PAD_IDX, TGT_PAD_IDX, device) #.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2e0686",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78b1425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_printoptions(precision=8, sci_mode=False)\n",
    "\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "checkpoint = 'C:/Users/CPB06GameN/Downloads/voiceprint/m2m100_418M'\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a1f6e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def PathConverter(path):\n",
    "    '''\n",
    "    r-string으로 넣어줘\n",
    "    '''\n",
    "    path = path.split('\\\\')\n",
    "    return path[-1], '/'.join(path[:-1])\n",
    "AIhub_file, folder_path = PathConverter(r\"C:\\ff\\test\\AIhub_total.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76fe2874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def LargeJsonToPandas(file_path, folder_path):\n",
    "    pat = '\"src_lang\":|\"src_text_raw\":|\"src_text\":|\"tgt_lang\":|\"tgt_text_raw\":|\"tgt_text\":|\"origin\":|\"domain\":'\n",
    "    oneobj = ''\n",
    "    with open(folder_path + '/' + file_path, 'r', encoding='utf-8') as f:\n",
    "        cnt = 0\n",
    "        for line in f:\n",
    "            if re.search(pat, str(line)) != None:\n",
    "                    if re.search('\"src_lang\":', str(line)) != None:\n",
    "                        oneobj += '{'\n",
    "                        oneobj += line.strip()\n",
    "                    elif re.search('\"domain\":', str(line)) != None:\n",
    "                        oneobj += line.strip()\n",
    "                        oneobj += '}\\n'\n",
    "                        cnt += 1\n",
    "                    else:\n",
    "                        oneobj += line.strip()\n",
    "            if cnt % 2000 == 0:\n",
    "                with open(folder_path + '/AIhub_pandas.json', 'a+', encoding='utf-8') as g:\n",
    "                    g.write(oneobj)\n",
    "                oneobj = ''\n",
    "            if str(line) == ']':\n",
    "                with open(folder_path + '/AIhub_pandas.json', 'a+', encoding='utf-8') as g:\n",
    "                    g.write(oneobj)\n",
    "            \n",
    "LargeJsonToPandas(AIhub_file, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1d41a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "class CustomDataset(IterableDataset):\n",
    "    def __init__(self, path, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.path = path\n",
    "    def __iter__(self):\n",
    "        chunksize = 5000\n",
    "        iter_json = pd.read_json(self.path, lines=True, chunksize=chunksize)\n",
    "        for chunk in iter_json:\n",
    "            for idx in range(chunksize):\n",
    "                length = []\n",
    "                idx = idx + chunk.index[0]\n",
    "                \n",
    "                self.tokenizer.src_lang = chunk['src_lang'][idx]\n",
    "                inputs = self.tokenizer(chunk['src_text'][idx], return_tensors='pt')\n",
    "                self.tokenizer.tgt_lang = chunk['tgt_lang'][idx]\n",
    "                with self.tokenizer.as_target_tokenizer():\n",
    "                    labels = self.tokenizer(chunk['tgt_text'][idx], return_tensors='pt').input_ids\n",
    "                inputs['labels'] = labels\n",
    "                \n",
    "                length = (v.shape[1] for k, v in inputs.items())\n",
    "                yield inputs, length\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "749a033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    device = 'cpu'\n",
    "    batch, length = zip(*batch)\n",
    "    ids, mask, label = zip(*length)\n",
    "    max_ids, max_mask, max_label = max(ids), max(mask), max(label)\n",
    "    ids, mask, label = list(ids), list(mask), list(label)\n",
    "    \n",
    "    ids_res, mask_res, label_res = [], [], []\n",
    "    for i, sample in enumerate(batch):\n",
    "        len_ids = max_ids - ids[i]\n",
    "        len_mask = max_mask - mask[i]\n",
    "        len_label = max_label - label[i]\n",
    "        ids_tensor = torch.cat([sample['input_ids'], torch.LongTensor([[tokenizer.pad_token_id] * len_ids], device=device)], dim=1)\n",
    "        mask_tensor = torch.cat([sample['attention_mask'], torch.LongTensor([[0] * len_mask], device=device)], dim=1)\n",
    "        label_tensor = torch.cat([sample['labels'], torch.LongTensor([[tokenizer.pad_token_id] * len_label], device=device)], dim=1)\n",
    "        ids_res.append(ids_tensor)\n",
    "        mask_res.append(mask_tensor)\n",
    "        label_res.append(label_tensor)\n",
    "    ids_batch = torch.cat(ids_res, dim=0)\n",
    "    mask_batch = torch.cat(mask_res, dim=0)\n",
    "    label_batch = torch.cat(label_res, dim=0)\n",
    "    return {'input_ids':ids_batch, 'attention_mask':mask_batch, 'labels':label_batch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db5dbc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = folder_path + '/' + 'AIhub_pandas.json'\n",
    "dataset = CustomDataset(path, tokenizer)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=4, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758e7966",
   "metadata": {},
   "source": [
    "## Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d7ff0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "teacher_model = M2M100ForConditionalGeneration.from_pretrained(checkpoint)\n",
    "optimizer = AdamW(student_model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epochs = 10\n",
    "# num_training_steps = num_epochs * len(dataloader)\n",
    "# lr_scheduler = get_scheduler('linear', optimizer=optimizer, num_warmup_steps=0, num_traning_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90837b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_kd(student_output, teacher_output, labels, params):\n",
    "    alpha, T = params\n",
    "    vocab_size = student_output.shape[-1]\n",
    "#     label = F.one_hot(labels, num_classes=vocab_size)\n",
    "    student_output = student_output.contiguous().view(-1, vocab_size)\n",
    "    labels = labels.contiguous().view(-1)\n",
    "    teacher_output = teacher_output.logits.contiguous().view(-1, vocab_size)\n",
    "    \n",
    "    student_loss = F.cross_entropy(student_output, labels) * (1. - alpha)\n",
    "    \n",
    "    soft_prediction = F.log_softmax(student_output / T, dim=1)\n",
    "    soft_labels = F.log_softmax(teacher_output / T, dim=1) * (alpha * T * T)\n",
    "    \n",
    "    distillation_loss = F.kl_div(soft_prediction, soft_labels, reduction='sum', log_target=True) * (T * T) / student_output.numel()\n",
    "    \n",
    "    loss = student_loss - distillation_loss * alpha\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "759b340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_len(path):\n",
    "    cnt = 0\n",
    "    with open(path, 'rb') as f:\n",
    "        for line in f:\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "tot_len = data_len(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73dd04c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kd(student_model, teacher_model, optimizer, loss_fn_kd, dataloader, params, total_length):\n",
    "    student_model.train()\n",
    "    teacher_model.eval()\n",
    "    \n",
    "    tmp, cnt = 0, 0\n",
    "    with tqdm(total=total_length) as t:\n",
    "        for batch in dataloader:\n",
    "            student_output = student_model(**batch)\n",
    "            if student_output != None:\n",
    "                with torch.no_grad():\n",
    "                    teacher_output = teacher_model(**batch)\n",
    "                \n",
    "                loss = loss_fn_kd(student_output, teacher_output, batch['labels'], params)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                tmp += loss.item()\n",
    "                cnt += 1\n",
    "                moving_loss = tmp / cnt \n",
    "                t.set_postfix(loss='{:05.3f}'.format(moving_loss))\n",
    "                t.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3600e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "params = (0.2, 0.2)\n",
    "for epoch in range(num_epochs):\n",
    "    train_kd(student_model, teacher_model, optimizer, loss_fn_kd, dataloader, params, tot_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f134cc8",
   "metadata": {},
   "source": [
    "### 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28c1ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "## Map-style Dataset은 random_split과 호환이 안 됨\n",
    "## 하지만 메모리가 충족하다면 __len__을 len(pd.read_json(self.path, lines=True))로 할 경우\n",
    "## working 가능할 수 있음\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer):\n",
    "        super().__init__()\n",
    "        self.path = path + '/'\n",
    "        self.file_list = os.listdir(path)\n",
    "        self.tokenizer = tokenizer\n",
    "    def file_sorter(self):\n",
    "        names = []\n",
    "        for file in self.file_list:\n",
    "            num = re.sub('[^0-9]', '', file)\n",
    "            names.append((int(num), file))\n",
    "        names.sort()\n",
    "        num, file_list = zip(*names)\n",
    "        return list(file_list)\n",
    "    def __len__(self):\n",
    "        files = self.file_sorter()\n",
    "        last = len(pd.read_json(self.path + files[-1]))\n",
    "        return ((len(self.file_list) - 1) * 10000) + last\n",
    "    def __getitem__(self, index):\n",
    "        cnt = 0\n",
    "        for file in self.file_list:\n",
    "            index = index - (cnt * 10000)\n",
    "            chunk = pd.read_json(self.path + file)\n",
    "            self.tokenizer.src_lang = chunk['src_lang'][index]\n",
    "            self.tokenizer.tgt_lang = chunk['tgt_lang'][index]\n",
    "            inputs = self.tokenizer(chunk['src_text'][index], return_tensors='pt') #.to(device)\n",
    "            with self.tokenizer.as_target_tokenizer():\n",
    "                labels = self.tokenizer(chunk['tgt_text'][index], return_tensors='pt').input_ids #.to(device)\n",
    "            inputs['labels'] = labels\n",
    "            length = (v.shape[1] for k, v in inputs.items())\n",
    "            cnt += 1\n",
    "            return inputs, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41afd746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def LargeJsonToPandas(folder_path, original_file_name, revised_file_name):\n",
    "    pat = '\"src_lang\":|\"src_text_raw\":|\"src_text\":|\"tgt_lang\":|\"tgt_text_raw\":|\"tgt_text\":|\"origin\":|\"domain\":'\n",
    "    with open(folder_path + '/' + original_file_name, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if re.search(pat, str(line)) != None:\n",
    "                with open(folder_path + '/' + f'{revised_file_name}', 'a+', encoding='utf-8') as g:\n",
    "                    if re.search('\"src_lang\":', str(line)) != None:\n",
    "                        g.write('{')\n",
    "                        g.write(line.strip())\n",
    "                    elif re.search('\"domain\":', str(line)) != None:\n",
    "                        g.write(line.strip())\n",
    "                        g.write('}\\n')\n",
    "                    else:\n",
    "                        g.write(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e24d31c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "## for 루프를 통제할 수 없음\n",
    "## index 와 루프가 동시에 맞물리지 않음\n",
    "## generator는 Iterable Dataset이 맞는 선택\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer, chunksize=10000):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.tokenizer = tokenizer\n",
    "        self.chunksize = chunksize\n",
    "    def __len__(self):\n",
    "        cnt = 0\n",
    "        with open(path, 'rb') as f:\n",
    "            for line in f:\n",
    "                cnt += 1\n",
    "        return cnt    \n",
    "#         return len(pd.read_json(self.path, lines=True))\n",
    "    def __getitem__(self, index):\n",
    "        data = pd.read_json(self.path, lines=True, chunksize=self.chunksize)\n",
    "        for chunk in data:\n",
    "            print(chunk['src_lang'])\n",
    "            self.tokenizer.src_lang = chunk['src_lang'][index]\n",
    "            self.tokenizer.tgt_lang = chunk['tgt_lang'][index]\n",
    "            inputs = self.tokenizer(chunk['src_text'][index], return_tensors='pt') #.to(device)\n",
    "            with self.tokenizer.as_target_tokenizer():\n",
    "                labels = self.tokenizer(chunk['tgt_text'][index], return_tensors='pt').input_ids #.to(device)\n",
    "            inputs['labels'] = labels\n",
    "            length = (v.shape[1] for k, v in inputs.items())\n",
    "            return inputs, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b36970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = folder_path + '/' + 'AIhub_pandas.json'\n",
    "dataset = CustomDataset(path, tokenizer)\n",
    "val_len = int(len(dataset) * 0.3)\n",
    "train, valid = random_split(dataset, [len(dataset)-val_len, val_len])\n",
    "train_dataloader = DataLoader(train, shuffle=True, batch_size=4, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5ca2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, length = spliter(dataset)\n",
    "train_dataloader = DataLoader(train, shuffle=True, batch_size=4, collate_fn=collate)\n",
    "\n",
    "def data_len(path):\n",
    "    cnt = 0\n",
    "    with open(path, 'rb') as f:\n",
    "        for line in f:\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def spliter(dataset):\n",
    "    train, valid = [], []\n",
    "    train_cnt, valid_cnt = 0, 0\n",
    "    for idx, data in enumerate(dataset):\n",
    "        if (idx+1) % 5000 != 0:\n",
    "            if random.uniform(0, 1) >= 0.75:\n",
    "                valid.append(data)\n",
    "                valid_cnt += 1\n",
    "            else:\n",
    "                train.append(data)\n",
    "                train_cnt += 1\n",
    "        else:\n",
    "            yield train, valid, (train_cnt, valid_cnt)\n",
    "            train, valid = [], []\n",
    "            train_cnt, valid_cnt = 0, 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "418.852px",
    "left": "920.531px",
    "right": "20px",
    "top": "120px",
    "width": "315px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
